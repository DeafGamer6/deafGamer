
@inproceedings{berke_preferred_2019,
	address = {New York, NY, USA},
	series = {{CHI} {EA} '19},
	title = {Preferred {Appearance} of {Captions} {Generated} by {Automatic} {Speech} {Recognition} for {Deaf} and {Hard}-of-{Hearing} {Viewers}},
	isbn = {978-1-4503-5971-9},
	url = {https://doi.org/10.1145/3290607.3312921},
	doi = {10.1145/3290607.3312921},
	abstract = {As the accuracy of Automatic Speech Recognition (ASR) nears human-level quality, it might become feasible as an accessibility tool for people who are Deaf and Hard of Hearing (DHH) to transcribe spoken language to text. We conducted a study using in-person laboratory methodologies, to investigate requirements and preferences for new ASR-based captioning services when used in a small group meeting context. The open-ended comments reveal an interesting dynamic between: caption readability (visibility of text) and occlusion (captions blocking the video contents). Our 105 DHH participants provided valuable feedback on a variety of caption-appearance parameters (strongly preferring familiar styles such as closed captions), and in this paper we start a discussion on how ASR captioning could be visually styled to improve text readability for DHH viewers.},
	urldate = {2022-11-16},
	booktitle = {Extended {Abstracts} of the 2019 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Berke, Larwan and Albusays, Khaled and Seita, Matthew and Huenerfauth, Matt},
	month = may,
	year = {2019},
	keywords = {automatic speech recognition, appearance, captioning, deaf and hard-of-hearing, user interface},
	pages = {1--6},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\9975XM2I\\Berke et al. - 2019 - Preferred Appearance of Captions Generated by Auto.pdf:application/pdf},
}

@article{butler_perspectives_2019,
	title = {Perspectives of deaf and hard of hearing viewers of captions},
	volume = {163},
	issn = {0002-726X},
	doi = {10.1353/aad.2019.0002},
	abstract = {Educational rights and other rights enumerated in federal law support deaf and hard of hearing (DHH) viewers’ access to captions in visual electronic media, yet uncaptioned and inadequately captioned media still exist. To determine what is satisfactory in captioned media and what could be improved to ensure access, data were gathered from focus group discussions with 20 DHH students who shared their perspectives on captions. The focus group analysis indicates that major topics of concern for DHH viewers include advocacy for captions and caption formatting preferences; the need for direct access to real-time videos, online videos, and other media; how captions influence and benefit DHH and hearing viewers; and captions’ importance in public, educational, and other social/cultural spaces. The author concludes that DHH viewers’ perspectives can help educators and advocates strengthen access to captions in education and society. © 2019, Gallaudet University Press. All rights reserved.},
	language = {English},
	number = {5},
	journal = {American Annals of the Deaf},
	author = {Butler, J.},
	year = {2019},
	keywords = {Media, Access, Captions, Technology},
	pages = {534--553},
}

@article{al_amin_preferences_2021,
	title = {Preferences of deaf or hard of hearing users for live-tv caption appearance},
	volume = {12769 LNCS},
	issn = {0302-9743},
	doi = {10.1007/978-3-030-78095-1_15},
	abstract = {There is a wide range of visual appearance of captions during television programming (e.g. text color, typeface, caption background, number of lines, caption placement), especially during live or near-live broadcasts in local markets. The effect of these visual properties of captions on Deaf and Hard of Hearing (DHH) users’ TV-watching experience have been less explored in existing research-based guidelines nor in the design of state-of-the-art caption evaluation metrics. Therefore, we empirically investigated what visual attributes of captions are preferred by DHH viewers while watching captioned live TV programs. We convened two focus groups where participants watched videos consisting of captions with various display properties and provided subjective open-ended feedback. By analyzing the focus-group responses, we observed DHH users’ preference for specific contrast between caption text and background color such as, black text on white background or vice-versa, and caption placement not occluding onscreen salient content. Our findings also revealed for preferences genre-adaptive caption typeface and movement during captioned live TV programming. © Springer Nature Switzerland AG 2021.},
	language = {English},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	author = {Al Amin, A. and Glasser, A. and Kushalnagar, R. and Vogler, C. and Huenerfauth, M.},
	year = {2021},
	note = {ISBN: 9783030780944},
	keywords = {Caption, Metric, Evaluation},
	pages = {189--201},
}

@article{butler_visual_2020,
	title = {The {Visual} {Experience} of {Accessing} {Captioned} {Television} and {Digital} {Videos}},
	volume = {21},
	issn = {1527-4764},
	doi = {10.1177/1527476418824805},
	abstract = {The increase in video-based communication has made different caption styles more apparent to audiences, including hearing viewers who watch social media videos with colorful open captions. To explore how viewers respond to a variety of caption styles, this article shares findings from three focus group discussions with twenty deaf and hard-of-hearing college students. This article begins by discussing the accessibility of captioned television and digital media and how captions can influence the viewing experience. This article then analyzes deaf and hard-of-hearing focus group participants’ statements about their viewing experiences, reception practices, and critiques of aesthetic and accessible caption styles. The analysis of viewers’ feedback reveals how the tension between various approaches to captions contributes to the reshaping of television and online media: a reshaping in which captions are coming to the forefront of the viewing experience for deaf, hard-of-hearing, and hearing viewers. © The Author(s) 2019.},
	language = {English},
	number = {7},
	journal = {Television and New Media},
	author = {Butler, J.},
	year = {2020},
	keywords = {television, video, access, new media, participation, visual studies},
	pages = {679--696},
}





@article{zahnert_differential_2011,
	title = {The {Differential} {Diagnosis} of {Hearing} {Loss}},
	volume = {108},
	issn = {1866-0452},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3139416/},
	doi = {10.3238/arztebl.2011.0433},
	abstract = {Background
According to the World Health Organization, hearing loss is one of the six leading contributors to the global burden of disease. It is becoming an ever more important problem in society at large, not just because the population is aging, but also because young people increasingly spend their leisure time in activities that expose them to excessive noise. On the other hand, the treatment of hearing loss is improving, as the result of technical developments in otological surgery, hearing aids, and cochlear implants. For nearly every type of hearing loss, there is now some type of rehabilitative treatment. The prerequisite to effective care is timely and accurate diagnosis.

Method
Review of the pertinent literature and national guidelines.

Results and Conclusion
The available epidemiological data on hearing loss in Germany are inadequate. It is roughly estimated that 13 to 14 million people in Germany are in need of treatment for hearing loss. The most common types of permanent hearing loss are those associated with old age, chronic otitis media, and acoustic trauma. Transient hearing loss is particularly common in childhood as a result of inadequate ventilation of the middle ear. The further technical development of cochlear implants has now widened their indications to include severe congenital deafness and presbycusis.},
	number = {25},
	urldate = {2023-05-02},
	journal = {Deutsches Ärzteblatt International},
	author = {Zahnert, Thomas},
	month = jun,
	year = {2011},
	pmid = {21776317},
	pmcid = {PMC3139416},
	pages = {433--444},
	file = {PubMed Central Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\5SHGHLR7\\Zahnert - 2011 - The Differential Diagnosis of Hearing Loss.pdf:application/pdf},
}



@article{chadha_world_2021,
	title = {The world report on hearing, 2021},
	volume = {99},
	issn = {0042-9686},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8085630/},
	doi = {10.2471/BLT.21.285643},
	number = {4},
	urldate = {2023-08-22},
	journal = {Bulletin of the World Health Organization},
	author = {Chadha, Shelly and Kamenov, Kaloyan and Cieza, Alarcos},
	month = apr,
	year = {2021},
	pmid = {33953438},
	pmcid = {PMC8085630},
	pages = {242--242A},
	file = {PubMed Central Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\KYT94UP3\\Chadha et al. - 2021 - The world report on hearing, 2021.pdf:application/pdf},
}

@inproceedings{da_silva_representing_2018,
	title = {Representing {Sentiment} {Using} {Colors} and {Particles} to {Provide} {Accessibility} for {Deaf} and {Hard} of {Hearing} {Players}},
	doi = {10.1109/SBGAMES.2018.00034},
	abstract = {Providing game accessibility to deaf or hard of hearing players is still an issue in the game industry. The most common access feature developed to provide accessibility for players with this type of disability is to implement closed captions and other textual information to detail sentiments. This paper presents another approach to this problem. Based on the study of colors, this work uses the particle system provided by Unity engine and combines these elements into different scenarios where colorful particles propagate in different directions and with different speeds and forms. This paper proposes that these scenarios can express different sentiments. The proposal evaluation was performed through user interviews. The results present a set of scenarios that can be used by game designers to visually express the intended sentiment of the music or game environment sounds and a Unity plugin that support this task.},
	booktitle = {2018 17th {Brazilian} {Symposium} on {Computer} {Games} and {Digital} {Entertainment} ({SBGames})},
	author = {da Silva, João Marcos Epifânio and Callado, Arthur de Castro and Jucá, Paulyne Matthews},
	month = oct,
	year = {2018},
	note = {ISSN: 2159-6662},
	keywords = {Visualization, Deafness, deaf, Auditory system, accessibility, Engines, Music, Ear, hard of hearing, game component, Games},
	pages = {221--22109},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\c1943213\\Zotero\\storage\\HA6WQEHU\\8636944.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\4PEMXLPH\\da Silva et al. - 2018 - Representing Sentiment Using Colors and Particles .pdf:application/pdf},
}

@inproceedings{broderick_importance_2018,
	title = {The {Importance} of {Spatial} {Audio} in {Modern} {Games} and {Virtual} {Environments}},
	doi = {10.1109/GEM.2018.8516445},
	abstract = {In Virtual Reality (VR), virtual environments, and gaming, audio greatly impacts the user, yet it is an area that has been under researched quite recently. While music and environmental sounds have been used to great effect throughout gaming history to craft a more immersive experience, spatial audio doesn't see as much focus. Not only does well made spatial audio allow a user to become more immersed in their virtual experience, it is an important channel for information about their environment. With the advent of VR, games are putting more work into spatial audio and audio design, and now the results are becoming available for both research and game development. This paper will look at not only why spatial audio can greatly improve virtual experiences, but also some of the new technologies that have become available in recent times which make the implementation of spatial audio far easier and of a higher quality than ever before. It will also look at some planned research to examine the advantages of spatial audio in sonified virtual environments using Unity 3D.},
	booktitle = {2018 {IEEE} {Games}, {Entertainment}, {Media} {Conference} ({GEM})},
	author = {Broderick, James and Duggan, Jim and Redfern, Sam},
	month = aug,
	year = {2018},
	keywords = {Task analysis, Engines, Three-dimensional displays, Games, Virtual environments, auditory display, game engine, Headphones, sonification, virtual environments, virtual reality},
	pages = {1--9},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\c1943213\\Zotero\\storage\\7JMIWTKQ\\8516445.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\94A4VRBJ\\Broderick et al. - 2018 - The Importance of Spatial Audio in Modern Games an.pdf:application/pdf},
}

@inproceedings{guillen_role_2021,
	address = {New York, NY, USA},
	series = {Academic {Mindtrek} '21},
	title = {The {Role} {Sound} {Plays} in {Games}: {A} {Thematic} {Literature} {Study} on {Immersion}, {Inclusivity} and {Accessibility} in {Game} {Sound} {Research}},
	isbn = {978-1-4503-8514-5},
	shorttitle = {The {Role} {Sound} {Plays} in {Games}},
	url = {https://doi.org/10.1145/3464327.3464365},
	doi = {10.1145/3464327.3464365},
	abstract = {As technologies and the sophistication of games evolve, so do the possibilities to immerse players in multi-sensorial experiences for different purposes and in different ways. The design and development of the auditory components of video games play an increasingly relevant immersive and inclusionary role within (and outside of) games. Sounds enable a deeper and more meaningful immersion, but also facilitate inclusion of and accessibility to people with different physical and psychological abilities. Sounds also provide a vehicle to challenge or overcome gender or even heritage stereotypes. Recognizing this potential, designers have often explored different means to facilitate accessibility, inclusion or sometimes intentionally challenging auditory experiences to users as, for example, seen in recent game releases where designers created a perceived mismatch between a character's voice and gender for inclusion beyond immersion. The present study aims to identify and thematically review relevant academic literature (47 studies), summarizing the perceived role of game sound design, its impact on immersion, and the way sound design enables (or hampers) inclusivity and accessibility within games. Our findings indicate that although there is research on how audio-related technology enhances immersion in games, studies about its use for increasingly relevant inclusive purposes (in terms of accessibility and social aspects like gender) are relatively scarce.},
	urldate = {2024-04-03},
	booktitle = {Proceedings of the 24th {International} {Academic} {Mindtrek} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Guillen, Georgina and Jylhä, Henrietta and Hassan, Lobna},
	month = sep,
	year = {2021},
	keywords = {Accessibility, Audio immersion, Inclusion in games, Sound design},
	pages = {12--20},
}


@article{brook_sound_nodate,
	title = {A sound idea: {An} investigation into accessible video game design for the deaf and hard of hearing},
	language = {en},
	author = {Brook, Luke James},
	file = {Brook - A sound idea An investigation into accessible vid.pdf:C\:\\Users\\c1943213\\Zotero\\storage\\Y4BLY2NV\\Brook - A sound idea An investigation into accessible vid.pdf:application/pdf},
}

@inproceedings{de_lacerda_pataca_visualization_2023,
	address = {New York, NY, USA},
	series = {{CHI} '23},
	title = {Visualization of {Speech} {Prosody} and {Emotion} in {Captions}: {Accessibility} for {Deaf} and {Hard}-of-{Hearing} {Users}},
	isbn = {978-1-4503-9421-5},
	shorttitle = {Visualization of {Speech} {Prosody} and {Emotion} in {Captions}},
	url = {https://doi.org/10.1145/3544548.3581511},
	doi = {10.1145/3544548.3581511},
	abstract = {Speech is expressive in ways that caption text does not capture, with emotion or emphasis information not conveyed. We interviewed eight Deaf and Hard-of-Hearing (dhh) individuals to understand if and how captions’ inexpressiveness impacts them in online meetings with hearing peers. Automatically captioned speech, we found, lacks affective depth, lending it a hard-to-parse ambiguity and general dullness. Interviewees regularly feel excluded, which some understand is an inherent quality of these types of meetings rather than a consequence of current caption text design. Next, we developed three novel captioning models that depicted, beyond words, features from prosody, emotions, and a mix of both. In an empirical study, 16 dhh participants compared these models with conventional captions. The emotion-based model outperformed traditional captions in depicting emotions and emphasis, with only a moderate loss in legibility, suggesting its potential as a more inclusive design for captions.},
	urldate = {2024-04-03},
	booktitle = {Proceedings of the 2023 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {de Lacerda Pataca, Caluã and Watkins, Matthew and Peiris, Roshan and Lee, Sooyeon and Huenerfauth, Matt},
	month = apr,
	year = {2023},
	keywords = {Accessibility, Emotion / Affective Computing, Empirical study that tells us about how people use a system, Individuals with Disabilities \& Assistive Technologies},
	pages = {1--15},
}


@inproceedings{de_lacerda_pataca_caption_2024,
	address = {New York, NY, USA},
	series = {{CHI} '24},
	title = {Caption {Royale}: {Exploring} the {Design} {Space} of {Affective} {Captions} from the {Perspective} of {Deaf} and {Hard}-of-{Hearing} {Individuals}},
	isbn = {979-8-4007-0330-0},
	shorttitle = {Caption {Royale}},
	url = {https://doi.org/10.1145/3613904.3642258},
	doi = {10.1145/3613904.3642258},
	abstract = {Affective captions employ visual typographic modulations to convey a speaker’s emotions, improving speech accessibility for Deaf and Hard-of-Hearing (dhh) individuals. However, the most effective visual modulations for expressing emotions remain uncertain. Bridging this gap, we ran three studies with 39 dhh\&nbsp; participants, exploring the design space of affective captions, which include parameters like text color, boldness, size, and so on. Study 1 assessed preferences for nine of these styles, each conveying either valence or arousal separately. Study 2 combined Study 1’s top-performing styles and measured preferences for captions depicting both valence and arousal simultaneously. Participants outlined readability, minimal distraction, intuitiveness, and emotional clarity as key factors behind their choices. In Study 3, these factors and an emotion-recognition task were used to compare how Study 2’s winning styles performed versus a non-styled baseline. Based on our findings, we present the two best-performing styles as design recommendations for applications employing affective captions.},
	urldate = {2024-07-16},
	booktitle = {Proceedings of the {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {de Lacerda Pataca, Caluã and Hassan, Saad and Tinker, Nathan and Peiris, Roshan Lalintha and Huenerfauth, Matt},
	month = may,
	year = {2024},
	pages = {1--17},
	file = {Full Text:C\:\\Users\\c1943213\\Zotero\\storage\\4A34ED6W\\de Lacerda Pataca et al. - 2024 - Caption Royale Exploring the Design Space of Affe.pdf:application/pdf},
}

@inproceedings{walia_haptech_2020,
	address = {Honolulu HI USA},
	title = {{HapTech}: {Exploring} {Haptics} in {Gaming} for the {Visually} {Impaired}},
	isbn = {978-1-4503-6819-3},
	shorttitle = {{HapTech}},
	url = {https://dl.acm.org/doi/10.1145/3334480.3381655},
	doi = {10.1145/3334480.3381655},
	language = {en},
	urldate = {2024-07-19},
	booktitle = {Extended {Abstracts} of the 2020 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Walia, Angel and Goel, Prakhar and Kairon, Varnika and Jain, Mayank},
	month = apr,
	year = {2020},
	pages = {1--6},
}

@article{power_validation_2021,
	title = {Validation and {Prioritization} of {Design} {Options} for {Accessible} {Player} {Experiences}},
	volume = {33},
	issn = {1873-7951},
	url = {https://doi.org/10.1093/iwc/iwac017},
	doi = {10.1093/iwc/iwac017},
	abstract = {The profile of accessible design of digital games has increased rapidly in both research and practice. Whereas at one time accessibility was a niche area of interest, it is now a key feature promoted in commercial gaming. Typically, games achieve accessibility by offering a range of options, both in settings and gameplay, that players can customize to meet their individual needs and preferences. However, there is a distinct lack of systematic data regarding the accessibility options that players prefer, how options can be prioritized in design or how options can impact player experience. This paper presents a study that collects data about options preferred by players and uses it to expand and validate a design vocabulary for accessible design in games. Further, the results point to a need to prioritize particular types of options, specifically those relating to the player-feedback loop of games, before implementing options that modify the challenges encountered by players.},
	number = {6},
	urldate = {2024-07-22},
	journal = {Interacting with Computers},
	author = {Power, Christopher and Cairns, Paul and Barlet, Mark and Haynes, Gregory and Beeston, Jen and DeHaven, Triskal},
	month = jul,
	year = {2021},
	pages = {641--656},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\VGKLSYSF\\Power et al. - 2021 - Validation and Prioritization of Design Options fo.pdf:application/pdf},
}

@inproceedings{porter_empirical_2013,
	address = {Bellevue Washington},
	title = {An empirical study of issues and barriers to mainstream video game accessibility},
	isbn = {978-1-4503-2405-2},
	url = {https://dl.acm.org/doi/10.1145/2513383.2513444},
	doi = {10.1145/2513383.2513444},
	language = {en},
	urldate = {2024-07-22},
	booktitle = {Proceedings of the 15th {International} {ACM} {SIGACCESS} {Conference} on {Computers} and {Accessibility}},
	publisher = {ACM},
	author = {Porter, John R. and Kientz, Julie A.},
	month = oct,
	year = {2013},
	pages = {1--8},
}

@article{powers_video_2015,
	title = {Video {Game} {Accessibility}: {A} {Legal} {Approach}},
	volume = {35},
	copyright = {Copyright (c) 2015 George Powers, Vinh Nguyen, Lex Frieden},
	issn = {2159-8371},
	shorttitle = {Video {Game} {Accessibility}},
	url = {https://dsq-sds.org/index.php/dsq/article/view/4513},
	doi = {10.18061/dsq.v35i1.4513},
	abstract = {Video game accessibility may not seem of significance to some, and it may sound trivial to anyone who does not play video games. This assumption is false. With the digitalization of our culture, video games are an ever increasing part of our life. They contribute to peer to peer interactions, education, music and the arts. A video game can be created by hundreds of musicians and artists, and they can have production budgets that exceed modern blockbuster films. Inaccessible video games are analogous to movie theaters without closed captioning or accessible facilities. The movement to have accessible video games is small, unorganized and misdirected. Just like the other battles to make society accessible were accomplished through legislation and law, the battle for video game accessibility must be focused toward the law and not the market.},
	language = {en},
	number = {1},
	urldate = {2024-07-22},
	journal = {Disability Studies Quarterly},
	author = {Powers, George and Nguyen, Vinh and Frieden, Lex},
	month = feb,
	year = {2015},
	note = {Number: 1},
	keywords = {technology, video games, Accessibility standards, Americans with Disabilities Act.},
}

@article{schuller_paralinguistics_2013,
	series = {Special issue on {Paralinguistics} in {Naturalistic} {Speech} and {Language}},
	title = {Paralinguistics in speech and language—{State}-of-the-art and the challenge},
	volume = {27},
	issn = {0885-2308},
	url = {https://www.sciencedirect.com/science/article/pii/S0885230812000162},
	doi = {10.1016/j.csl.2012.02.005},
	abstract = {Paralinguistic analysis is increasingly turning into a mainstream topic in speech and language processing. This article aims to provide a broad overview of the constantly growing field by defining the field, introducing typical applications, presenting exemplary resources, and sharing a unified view of the chain of processing. It then presents the first broader Paralinguistic Challenge organised at INTERSPEECH 2010 by the authors including a historical overview of the Challenge tasks of recognising age, gender, and affect, a summary of methods used by the participants, and their results. In addition, we present the new benchmark obtained by fusion of participants’ predictions and conclude by discussing ten recent and emerging trends in the analysis of paralinguistics in speech and language.},
	number = {1},
	urldate = {2024-07-23},
	journal = {Computer Speech \& Language},
	author = {Schuller, Björn and Steidl, Stefan and Batliner, Anton and Burkhardt, Felix and Devillers, Laurence and Müller, Christian and Narayanan, Shrikanth},
	month = jan,
	year = {2013},
	keywords = {Affect, Age, Challenge, Gender, Paralinguistics, Survey, Trends},
	pages = {4--39},
	file = {Submitted Version:C\:\\Users\\c1943213\\Zotero\\storage\\AFKR2XD9\\Schuller et al. - 2013 - Paralinguistics in speech and language—State-of-th.pdf:application/pdf},
}

@inproceedings{ouhyoung_force_1995,
	title = {A {Force} {Feedback} {Joystick} and {Its} {Use} in {PC} {Video} {Games}},
	url = {https://ieeexplore.ieee.org/document/518008},
	doi = {10.1109/ICCE.1995.518008},
	urldate = {2024-07-23},
	booktitle = {Proceedings of {International} {Conference} on {Consumer} {Electronics}},
	author = {Ouhyoung, Ming and Wu, Jiann-Rong and Tsai, Wu-Nan and Yang, Tzong-Jer and Huang, Chung-Hsi},
	month = jun,
	year = {1995},
	keywords = {Auditory displays, Costs, Games, Acceleration, DC motors, Force feedback, Haptic interfaces, Iron, Torque, Viscosity},
	pages = {326--},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\V6F5Q72Z\\Ouhyoung et al. - 1995 - A Force Feedback Joystick and Its Use in PC Video .pdf:application/pdf},
}

@inproceedings{tappeiner_good_2009,
	title = {Good vibrations: {Asymmetric} vibrations for directional haptic cues},
	shorttitle = {Good vibrations},
	url = {https://ieeexplore.ieee.org/document/4810863},
	doi = {10.1109/WHC.2009.4810863},
	abstract = {In this paper we present a new concept for haptic guidance in multiple dimensions, in the form of asymmetric vibrations. We show that by adding asymmetry, vibrations from a single source can, like continuous forces, provide effective, high-resolution directional haptic cues in multiple dimensions. Unlike feedback via continuous forces, vibrations can be generated in an almost arbitrarily small workspace. After describing the concept in detail, we describe a user study that assesses the effects of such vibrations - applied to subjects' hands - on their ability to distinguish between different directions. The results indicate that asymmetric vibrations can provide accurate directional haptic feedback.},
	urldate = {2024-07-29},
	booktitle = {World {Haptics} 2009 - {Third} {Joint} {EuroHaptics} conference and {Symposium} on {Haptic} {Interfaces} for {Virtual} {Environment} and {Teleoperator} {Systems}},
	author = {Tappeiner, Hanns W. and Klatzky, Roberta L. and Unger, Bert and Hollis, Ralph},
	month = mar,
	year = {2009},
	keywords = {Robots, Vibrations, Psychology, Acceleration, Force feedback, Haptic interfaces, Cities and towns, Teleoperators, Transducers, Virtual environment},
	pages = {285--289},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\YIQFHLVY\\Tappeiner et al. - 2009 - Good vibrations Asymmetric vibrations for directi.pdf:application/pdf},
}

@inproceedings{salazar_motion_2016,
	title = {Motion guidance using {Haptic} {Feedback} based on vibrotactile illusions},
	url = {https://ieeexplore.ieee.org/document/7759689},
	doi = {10.1109/IROS.2016.7759689},
	abstract = {In this paper we present a wearable Haptic Feedback Device to convey intuitive motion direction to the user through haptic feedback based on vibrotactile illusions. Vibrotactile illusions occur on the skin when two or more vibrotactile actuators in proximity are actuated in coordinated sequence, causing the user to feel combined sensations, instead of separate ones. By combining these illusions we can produce various sensation patterns that are discernible by the user, thus allowing to convey different information with each pattern. A method to provide information about direction through vibrotactile illusions is introduced on this paper. This method uses a grid of vibrotactile actuators around the arm actuated in coordination. The sensation felt on the skin is consistent with the desired direction of motion, so the desired motion can be intuitively understood. We show that the users can recognize the conveyed direction, and implemented a proof of concept of the proposed method to guide users' elbow flexion/extension motion.},
	urldate = {2024-07-29},
	booktitle = {2016 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Salazar, Jose and Hirata, Yasuhisa and Kosuge, Kazuhiro},
	month = oct,
	year = {2016},
	note = {ISSN: 2153-0866},
	keywords = {Skin, Training, Vibrations, Haptic interfaces, Actuators, Elbow, Semiconductor optical amplifiers},
	pages = {4685--4691},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\Z9HPU2Y2\\Salazar et al. - 2016 - Motion guidance using Haptic Feedback based on vib.pdf:application/pdf},
}

@article{braun_one_2021,
	title = {One size fits all? {What} counts as quality practice in (reflexive) thematic analysis?},
	volume = {18},
	issn = {1478-0887},
	shorttitle = {One size fits all?},
	url = {https://doi.org/10.1080/14780887.2020.1769238},
	doi = {10.1080/14780887.2020.1769238},
	abstract = {Developing a universal quality standard for thematic analysis (TA) is complicated by the existence of numerous iterations of TA that differ paradigmatically, philosophically and procedurally. This plurality in TA is often not recognised by editors, reviewers or authors, who promote ‘coding reliability measures’ as universal requirements of quality TA. Focusing particularly on our reflexive TA approach, we discuss quality in TA with reference to ten common problems we have identified in published TA research that cites or claims to follow our guidance. Many of the common problems are underpinned by an assumption of homogeneity in TA. We end by outlining guidelines for reviewers and editors – in the form of twenty critical questions – to support them in promoting high(er) standards in TA research, and more deliberative and reflexive engagement with TA as method and practice.},
	number = {3},
	urldate = {2025-01-16},
	journal = {Qualitative Research in Psychology},
	author = {Braun, Virginia and Clarke, Victoria},
	month = jul,
	year = {2021},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/14780887.2020.1769238},
	pages = {328--352},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\YS44SMIJ\\Braun and Clarke - 2021 - One size fits all What counts as quality practice in (reflexive) thematic analysis.pdf:application/pdf},
}

@phdthesis{brook_sound_2017,
	title = {A sound idea: {An} investigation into accessible video game design for the deaf and hard of hearing},
	shorttitle = {A sound idea},
	abstract = {Full Text: http://ro.ecu.edu.au/cgi/viewcontent.cgi?article=2986\&context=theses

A widely accepted, and incorrect, assumption towards hearing accessibility in video games is that deaf and hard of hearing (DHH) users are those who encounter the least barriers and are generally well catered for. Rapid advancement in video game technology has seen video game sound evolve from simple blips generated by internal circuitry to fully realised digital audio used to convey critical information. To accommodate the DHH, this information needs to be conveyed in an alternative manner. However, evidence suggests existing accessible design solutions for the DHH lack specificity and are insufficient. Thus, the inability to hear, or hear well, has historically resulted in DHH users left with impeded experience and gameplay.

This thesis describes an investigation to address the primary research question: How might accessible video game design practices be facilitated to better accommodate the deaf and hard of hearing? To examine this question, an action research method as part of a transformative mixed methods methodology was used. Data collection procedures included critical analysis of literature, observations, and a cross-sectional self-administered survey for triangulation.

The critical analysis of literature exposed issues relating to accessible video game design, particularly in relation to the identification of solutions and technical implementation. Further, issues related to the classification of video game software were identified. This posed potential problems with identification of game design methods and led to the development of a new video game classification model. The new model informed an analysis on the methods used for the design of video games, and results were visually represented and mapped to the different approaches to accessible design. Subsequent analysis determined that a game assessment framework is a suitable approach to facilitating accessible design.

Further investigation identified visual feedback as the most suitable form of complementary feedback to game audio. This led to the development of a new model to classify visual feedback elements used in video games, and identification of audio feedback categories based on diegetic film theory. Through triangulation of results, a new game feedback model (GFM) was developed.

The GFM was used for observational experimentation to identify and classify individual visual feedback elements used in video games. Each element was analysed and mapped to categories of game sound. The resulting model, with populated data, was used to determine what visual feedback elements may be used to complement specific categories of critical game audio. A survey was subsequently used for triangulation, and resulted in amendments to the final model.

Through iterative development, and interpretation of findings, the research culminated in the development of a game assessment framework. The three-step framework aids in the classification of game sounds; assesses the impact of those game sounds; and provides recommendations for complementary visual feedback elements for sounds identified as having an adverse impact on user experience and gameplay if they were to be removed. The framework is innovative and has the potential to provide practical guidance for developers of video games. In addition, this research provides the foundation for future research, with the potential to influence accessible game design for the DHH.},
	author = {Brook, Luke},
	month = jul,
	year = {2017},
}

@book{haddad_visual_2019,
	title = {Visual {Substitutes} for {Audio} {Cues} - {Providing} situational awareness for players with auditory disabilities},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:mau:diva-20123},
	abstract = {DiVA portal is a finding tool for research publications and student theses written at the following 50 universities and research institutions.},
	language = {eng},
	urldate = {2025-01-16},
	publisher = {Malmö universitet/Teknik och samhälle},
	author = {Haddad, David and Strand, Casper},
	year = {2019},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\PIFJ4JRM\\Haddad and Strand - 2019 - Visual Substitutes for Audio Cues - Providing situational awareness for players with auditory disabi.pdf:application/pdf},
}


@inproceedings{leavitt_ping_2016,
	address = {New York, NY, USA},
	series = {{CHI} '16},
	title = {Ping to {Win}? {Non}-{Verbal} {Communication} and {Team} {Performance} in {Competitive} {Online} {Multiplayer} {Games}},
	isbn = {978-1-4503-3362-7},
	shorttitle = {Ping to {Win}?},
	url = {https://dl.acm.org/doi/10.1145/2858036.2858132},
	doi = {10.1145/2858036.2858132},
	abstract = {Non-verbal communication plays a large role in online competitive multiplayer games, as team members attempt to coordinate with each other without distraction to achieve victory. Some games enable this communication through "pings," alerts that are easy to activate and provide auditory and visual cues for teammates. In this paper, we review the literature on gestures and non-verbal communication and, through an empirical analysis of 84,489 players across 10,293 matches in the popular game, League of Legends, illustrate ping use in multiplayer games and test the impact of ping actions on performance in teams. We show that the amount of pings depends on player role and in-game activity and that pings by players have a positive but concave relationship with player performance. These findings demonstrate the importance of non-verbal communication and interruption on the performance of virtual team members. We conclude by discussing the implications of these results for theorizing and designing sociotechnical systems that rely on users to engage in synchronous, collaborative work in shared visual spaces.},
	urldate = {2025-04-29},
	booktitle = {Proceedings of the 2016 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {Association for Computing Machinery},
	author = {Leavitt, Alex and Keegan, Brian C. and Clark, Joshua},
	month = may,
	year = {2016},
	pages = {4337--4350},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\NQLVIINT\\Leavitt et al. - 2016 - Ping to Win Non-Verbal Communication and Team Performance in Competitive Online Multiplayer Games.pdf:application/pdf},
}

@inproceedings{lee_less_2025,
	address = {Yokohama Japan},
	title = {Less {Talk}, {More} {Trust}: {Understanding} {Players}' {In}-game {Assessment} of {Communication} {Processes} in {League} of {Legends}},
	isbn = {979-8-4007-1394-1},
	shorttitle = {Less {Talk}, {More} {Trust}},
	url = {https://dl.acm.org/doi/10.1145/3706598.3714226},
	doi = {10.1145/3706598.3714226},
	language = {en},
	urldate = {2025-06-02},
	booktitle = {Proceedings of the 2025 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Lee, Juhoon and Kim, Seoyoung and Park, Yeon Su and Kim, Juho and Jang, Jeong-woo and Seering, Joseph},
	month = apr,
	year = {2025},
	pages = {1--17},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\55PDB2UY\\Lee et al. - 2025 - Less Talk, More Trust Understanding Players' In-game Assessment of Communication Processes in Leagu.pdf:application/pdf},
}

@inproceedings{wuertz_why_2017,
	address = {Denver Colorado USA},
	title = {Why {Players} use {Pings} and {Annotations} in {Dota} 2},
	isbn = {978-1-4503-4655-9},
	url = {https://dl.acm.org/doi/10.1145/3025453.3025967},
	doi = {10.1145/3025453.3025967},
	language = {en},
	urldate = {2025-06-02},
	booktitle = {Proceedings of the 2017 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Wuertz, Jason and Bateman, Scott and Tang, Anthony},
	month = may,
	year = {2017},
	pages = {1978--2018},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\FEBCQHRL\\Wuertz et al. - 2017 - Why Players use Pings and Annotations in Dota 2.pdf:application/pdf},
}

@article{wadley_voice_2014,
	title = {Voice in {Virtual} {Worlds}: {The} {Design}, {Use}, and {Influence} of {Voice} {Chat} in {Online} {Play}},
	volume = {30},
	issn = {0737-0024},
	shorttitle = {Voice in {Virtual} {Worlds}},
	url = {https://www.academia.edu/70081728/Voice_in_Virtual_Worlds_The_Design_Use_and_Influence_of_Voice_Chat_in_Online_Play},
	doi = {10.1080/07370024.2014.987346},
	abstract = {Communication is a critical aspect of any collaborative system. In online multiplayer games and virtual worlds it is especially complex. Users are present over long periods and require both synchronous and asynchronous communication, but may prefer},
	number = {3-4},
	urldate = {2025-06-02},
	journal = {Human–Computer Interaction},
	author = {Wadley, Greg and Carter, Marcus and Gibbs, Martin},
	year = {2014},
	pages = {336},
}

@article{woll_cultural_1998,
	title = {Cultural and {Language} {Diversity} and the {Deaf} {Experience}},
	volume = {2},
	issn = {1367-0069},
	url = {https://doi.org/10.1177/136700699800200107},
	doi = {10.1177/136700699800200107},
	language = {en},
	number = {1},
	urldate = {2025-01-16},
	journal = {International Journal of Bilingualism},
	author = {Woll, Bencie},
	month = mar,
	year = {1998},
	note = {Publisher: SAGE Publications Ltd},
	pages = {104--105},
}

@incollection{miesenberger_game_2018,
	address = {Cham},
	title = {Game {Accessibility} {Guidelines} and {WCAG} 2.0 – {A} {Gap} {Analysis}},
	volume = {10896},
	isbn = {978-3-319-94276-6 978-3-319-94277-3},
	url = {https://link.springer.com/10.1007/978-3-319-94277-3_43},
	abstract = {Game accessibility is to remove unnecessary barriers for people with disabilities (PwD), within the limitation of game rules. Canvas in HTML5 and WebGL means that virtually every web browser is a game runtime environment. The problem is that web-based games can only be optimised to follow WCAG within limits of game rules and WCAG may not include what is needed for accessible games. The W3C Silver Taskforce is at the time of this writing preparing the next version of WCAG. This paper compares WCAG 2.0 and a set of current game accessibility guidelines (GAG), to answer: (1) Which similarities and diﬀerences can be found between WCAG 2.0 and GAG?; (2) How may these diﬀerences inform the W3C Silver Taskforce in the ongoing work to prepare the next version of WCAG?; and (3) How could the optimisation for accessibility in web-based games be performed? 107 GAGs were compared with WCAG 2.0, resulting in 61 survey questions plus comments and demographics, sent to experts and other users of WCAG. Semi-structured interviews were also conducted. Conclusions are that there is a clear gap but WCAG 2.1 bridges a few parts. Furthermore, the study seems relevant for the Silver Taskforce in understanding the demarcation line between apps in general and games and possibly for how extended reality applications could be made more accessible.},
	language = {en},
	urldate = {2024-04-18},
	booktitle = {Computers {Helping} {People} with {Special} {Needs}},
	publisher = {Springer International Publishing},
	author = {Westin, Thomas and Ku, JaEun Jemma and Dupire, Jérôme and Hamilton, Ian},
	editor = {Miesenberger, Klaus and Kouroupetroglou, Georgios},
	year = {2018},
	doi = {10.1007/978-3-319-94277-3_43},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {270--279},
	file = {Westin et al. - 2018 - Game Accessibility Guidelines and WCAG 2.0 – A Gap.pdf:C\:\\Users\\c1943213\\Zotero\\storage\\7CHKRDTM\\Westin et al. - 2018 - Game Accessibility Guidelines and WCAG 2.0 – A Gap.pdf:application/pdf},
}

@article{bat-chava_diversity_2000,
	title = {Diversity of {Deaf} {Identities}},
	volume = {145},
	issn = {1543-0375},
	url = {https://muse.jhu.edu/article/384063},
	doi = {10.1353/aad.2012.0176},
	abstract = {Social Identity Theory (Tajfel, 1981) posits that members of minority groups achieve positive social identity by (a) attempting to gain access to the mainstream through individual mobility or (b) working with other group members to bring about social change. Some people may use a combination of both strategies. Through the use of cluster analysis, the existence of three identities associated with these strategies was discerned in a sample of 267 deaf adults: culturally hearing identity, culturally deaf identity, and bicultural identity, each comprising about a third of the sample. A subset of 56 people were interviewed in depth; excerpts are presented to illustrate the identity types. Qualified support was found for the prediction that people with culturally deaf and bicultural identities would have higher self-esteem.},
	language = {en},
	number = {5},
	urldate = {2024-07-25},
	journal = {American Annals of the Deaf},
	author = {Bat-Chava, Yael},
	month = dec,
	year = {2000},
	pages = {420--428},
}

@inproceedings{rogers_effects_2019,
	address = {New York, NY, USA},
	series = {{CHI} {PLAY} '19},
	title = {Effects of {Background} {Music} on {Risk}-{Taking} and {General} {Player} {Experience}},
	isbn = {978-1-4503-6688-5},
	url = {https://dl.acm.org/doi/10.1145/3311350.3347158},
	doi = {10.1145/3311350.3347158},
	abstract = {Music affects our emotions and behaviour in real life, yet despite its prevalence in games, we have a limited understanding of its potential as a tool to explicitly influence player experience and behaviour in games. In this work, we investigate whether we can affect players' risk-taking behaviour through the presence and attributes of background music. We built a game that operationalizes risk behaviour by repeatedly giving players the choice between a safe but less rewarding course, and a risky but potentially more rewarding course. In a mixed-design user study (N=60), we explored the impact of music presence, tempo, and affective inflection on players' in-game risk behaviour and overall player experience. We found an effect of music presence on risk behaviour in the first playthrough, i.e., in the absence of other prior knowledge about the game. Further, music affect and tempo affected player immersion, as well as experienced mastery and challenge. Based on these findings, we discuss implications for game design and future research directions.},
	urldate = {2023-11-08},
	booktitle = {Proceedings of the {Annual} {Symposium} on {Computer}-{Human} {Interaction} in {Play}},
	publisher = {Association for Computing Machinery},
	author = {Rogers, Katja and Jörg, Matthias and Weber, Michael},
	month = oct,
	year = {2019},
	keywords = {music, immersion, player experience, game audio, player behaviour, risk-taking},
	pages = {213--224},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\ZTIR5UKQ\\Rogers et al. - 2019 - Effects of Background Music on Risk-Taking and Gen.pdf:application/pdf},
}

@inproceedings{rogers_audio_2019,
	address = {New York, NY, USA},
	series = {{AM} '19},
	title = {Audio {Habits} and {Motivations} in {Video} {Game} {Players}},
	isbn = {978-1-4503-7297-8},
	url = {https://dl.acm.org/doi/10.1145/3356590.3356599},
	doi = {10.1145/3356590.3356599},
	abstract = {Game music is increasingly being explored in terms of empirical effects on players, but we know very little about how players actually perceive and use background music in games, and why. We conducted a survey (N=737) to gain an understanding of players' in-the-wild audio habits and motivations, which can inform future research and industry practices regarding game audio design. The results indicate a wide variance in players' estimation of the importance of music in games. Further, we identify and provide evidence for the comparatively new multitasking phenomenon: a substantial number of players who do not listen to games' provided background music, often in favour of additional/parallel media usage. Based on these findings, we discuss implications for game audio design, ground existing common knowledge with empirical support, and delineate future research directions.},
	urldate = {2023-11-08},
	booktitle = {Proceedings of the 14th {International} {Audio} {Mostly} {Conference}: {A} {Journey} in {Sound}},
	publisher = {Association for Computing Machinery},
	author = {Rogers, Katja and Weber, Michael},
	month = sep,
	year = {2019},
	keywords = {music, games, audio, in-the-wild, player motivations},
	pages = {45--52},
	file = {Full Text PDF:C\:\\Users\\c1943213\\Zotero\\storage\\4D2WQBH2\\Rogers and Weber - 2019 - Audio Habits and Motivations in Video Game Players.pdf:application/pdf},
}

\\@misc{Fortnite,
    Author = {Epic Games},
    Publisher = {Epic Games},
    Title = {\emph{Fortnite}},
    Year = {2017}
}

@misc{Halo_MCC,
    Author = {343 Industries},
    Publisher = {Xbox Game Studios},
    Title = {\emph{Halo: the Master Chief Collection}},
    Year = {2014}
}

@misc{FH5,
    Author = {Playground games},
    Publisher = {Xbox Game Studios},
    Title = {\emph{Forza Horizon 5}},
    Year = {2023}
}

@misc{CS2,
    Author = {Valve},
    Publisher = {Valve},
    Title = {\emph{Counter Strike 2}},
    Year = {2023}
}

@misc{FFXIV,
    Author = {Square Enix},
    Publisher = {square Enix},
    Title = {\emph{Final Fantasy XIV}},
    Year = {2010}
}

@misc{CoD,
    Author = {Activision},
    Publisher = {Activision},
    Title = {\emph{Call of Duty}},
    Year = {2023}
}

@misc{LoL,
    Author = {Riot Games},
    Publisher = {Riot Games},
    Title = {\emph{League of Legends}},
    Year = {2009}
}

@misc{Overwatch,
    Author = {Blizzard Entertainment},
    Publisher = {Blizzard Entertainment},
    Title = {\emph{Overwatch}},
    Year = {2016}
}

@misc{noauthor_game_nodate,
	title = {Game accessibility guidelines {\textbar} {A} straightforward reference for inclusive game design},
    author = {GAG},
	url = {https://gameaccessibilityguidelines.com/},
	language = {en-US},
	urldate = {2024-04-18},
	file = {Snapshot:C\:\\Users\\c1943213\\Zotero\\storage\\NUYI5Y2M\\gameaccessibilityguidelines.com.html:text/html},
}

@misc{noauthor_w3c_nodate,
	title = {{W3C}},
	url = {https://www.w3.org/},
    author = {W3C},
	abstract = {The World Wide Web Consortium (W3C) develops standards and guidelines to help everyone build a web based on the principles of accessibility, internationalization, privacy and security.},
	language = {en},
	urldate = {2024-04-18},
	journal = {W3C},
	file = {Snapshot:C\:\\Users\\c1943213\\Zotero\\storage\\XQY93KG2\\www.w3.org.html:text/html},
}

@misc{noauthor_21st_2021,
	title = {21st {Century} {Communications} and {Video} {Accessibility} {Act} ({CVAA}) {\textbar} {Federal} {Communications} {Commission}},
	url = {https://www.fcc.gov/consumers/guides/21st-century-communications-and-video-accessibility-act-cvaa},
	abstract = {The Twenty-First Century Communications and Video Accessibility Act (CVAA) updates federal communications law to increase the access of persons with disabilities to modern communications.},
	language = {en},
	urldate = {2024-04-03},
    author = {CVAA},
	month = jan,
	year = {2021},
}